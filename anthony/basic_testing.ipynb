{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(4)\n",
    "print('Sleep 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ['https://github.com/pewresearch/pewanalytics', 'https://github.com/texastribune/scuole', 'https://github.com/texastribune/thermometer', 'https://github.com/texastribune/walls', 'https://github.com/texastribune/geoip2', 'https://github.com/texastribune/queso-tools', 'https://github.com/texastribune/django-locking', 'https://github.com/texastribune/data-visuals-create', 'https://github.com/texastribune/tacobots', 'https://github.com/newscorp-ghfb/validates_timeliness','https://github.com/newscorp-ghfb/rbenv-cookbook','https://github.com/newscorp-ghfb/geogle']\n",
    "\n",
    "url2 = ['https://github.com/pewresearch/pewtils', 'https://github.com/pewresearch/search_sampler', 'https://github.com/gawkermedia/kinja-post-gem', 'https://github.com/bloomberg/chef-bcpc', 'https://github.com/bloomberg/locking_resource-cookbook', 'https://github.com/bloomberg/collectd-cookbook', 'https://github.com/bloomberg/nginx-cookbook', 'https://github.com/bloomberg/consul-cluster-cookbook', 'https://github.com/bloomberg/cobbler-cookbook', 'https://github.com/bloomberg/openbfdd-cookbook', 'https://github.com/newscorp-ghfb/kaminari']\n",
    "\n",
    "url3 = ['https://github.com/bloomberg/chef-bcs', 'https://github.com/bloomberg/zookeeper-cookbook', 'https://github.com/bloomberg/confd-cookbook', 'https://github.com/bloomberg/collectd_plugins-cookbook', 'https://github.com/bloomberg/kubernetes-cluster-cookbook', 'https://github.com/nytimes/nytcampfin', 'https://github.com/techcrunch/json_printer', 'https://github.com/observermedia/realgraph-listener', 'https://github.com/observermedia/django-wordpress-rest', 'https://github.com/thenextweb/passgenerator']\n",
    "\n",
    "url4 = ['https://github.com/thenextweb/amp-wp', 'https://github.com/thenextweb/laravel-elasticsearch', 'https://github.com/thenextweb/slack-laravel', 'https://github.com/thenextweb/craft-3-adminbar', 'https://github.com/npr/frank', 'https://github.com/thenextweb/Embed', 'https://github.com/thenextweb/oembed', 'https://github.com/thenextweb/flatten', 'https://github.com/thenextweb/curl', 'https://github.com/npr/php-image-optim', 'https://github.com/texastribune/top10pct', 'https://github.com/texastribune/newsapps-app-kit']\n",
    "\n",
    "url5 = ['https://github.com/thenextweb/cro', 'https://github.com/npr/node-randomstring', 'https://github.com/texastribune/tx_salaries', 'https://github.com/texastribune/the-dp', 'https://github.com/texastribune/tx_lege_districts', 'https://github.com/texastribune/tt_social_auth', 'https://github.com/texastribune/armstrong.core.tt_sections', 'https://github.com/texastribune/aeis', 'https://github.com/texastribune/ox-scale', 'https://github.com/texastribune/django-gistpage', 'https://github.com/newscorp-ghfb/sidekiq-throttler']\n",
    "\n",
    "url6 = ['https://github.com/theatlantic/django-nested-admin', 'https://github.com/theatlantic/django-xml', 'https://github.com/theatlantic/django-select2-forms', 'https://github.com/theatlantic/django-admin-locking', 'https://github.com/texastribune/lethal-drug-tracker', 'https://github.com/texastribune/txlege-camera-status', 'https://github.com/texastribune/postcss-amp', 'https://github.com/texastribune/talk', 'https://github.com/texastribune/code-grabber', 'https://github.com/texastribune/react-external-boilerplate']\n",
    "\n",
    "url7 = ['https://github.com/voxmedia/vc-ikea-minisite', 'https://github.com/voxmedia/viz-app', 'https://github.com/voxmedia/prebid.github.io', 'https://github.com/voxmedia/Transcriber', 'https://github.com/voxmedia/userstamp', 'https://github.com/voxmedia/gliss', 'https://github.com/nbcnews/octopus-vr', 'https://github.com/texastribune/donations-app', 'https://github.com/texastribune/djangocms-text-ckeditor', 'https://github.com/texastribune/newsapps-styleguide-2.0', 'https://github.com/texastribune/500', 'https://github.com/WSJ/pinpoint-editor', 'https://github.com/WSJ/ballot-tally']\n",
    "\n",
    "url8 = ['https://github.com/texastribune/txlege84', 'https://github.com/texastribune/donation-builder', 'https://github.com/abcnews/scrollyteller', 'https://github.com/abcnews/odyssey-scrollyteller', 'https://github.com/abcnews/data-life', 'https://github.com/abcnews/interactive-ssm-map', 'https://github.com/ajam/chartbuilder-electron', 'https://github.com/WSJ/scroll-watcher', 'https://github.com/WSJ/two-step', 'https://github.com/texastribune/faces-of-death-row', 'https://github.com/texastribune/text-balancer', 'https://github.com/WSJ/squaire']\n",
    "\n",
    "url9 = ['https://github.com/WSJ/the-meta-tag-checker', 'https://github.com/npr/nprapi-wordpress', 'https://github.com/npr/npr-one-backend-proxy-php', 'https://github.com/npr/pmp-wordpress-plugin', 'https://github.com/npr/pmp-php-sdk', 'https://github.com/npr/pmp-drupal-plugin', 'https://github.com/npr/zaphpa', 'https://github.com/npr/silverstripe-opauth', 'https://github.com/npr/Slim']\n",
    "\n",
    "urls= url+url2+url3+url4+url5+url6+url7+url8+url9\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://github.com/thenextweb/cro', \n",
    "'https://github.com/thenextweb/jQuery-Search', \n",
    "'https://github.com/texastribune/tx_salaries', \n",
    "'https://github.com/texastribune/the-dp', \n",
    "'https://github.com/texastribune/tx_lege_districts', \n",
    "'https://github.com/texastribune/tt_social_auth', \n",
    "'https://github.com/texastribune/armstrong.core.tt_sections', \n",
    "'https://github.com/texastribune/aeis', \n",
    "'https://github.com/texastribune/ox-scale', \n",
    "'https://github.com/texastribune/django-gistpage', \n",
    "'https://github.com/newscorp-ghfb/sidekiq-throttler'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_gitmds():\n",
    "    '''\n",
    "    Creates a list of various GitRepos urls from various news media orginizations, and then scrapes the text from their readmes and codes\n",
    "    block to generate a json dictionary file that looks like {\"body\":text from the readme, \"top_code\":the first entry from the code block}.\n",
    "    * File name generated is gitMDs.json\n",
    "    * If file exists it will read the file into a dataframe\n",
    "    * If the file does not exist it will create the file (outlined above) and will return the dataframe\n",
    "\n",
    "    Note - The initial file creation time is ~3min and 30secs. The file has been included in this repo due to that.\n",
    "    '''\n",
    "\n",
    "    url = ['https://github.com/pewresearch/pewanalytics', 'https://github.com/texastribune/scuole', 'https://github.com/texastribune/thermometer', 'https://github.com/texastribune/walls', 'https://github.com/texastribune/geoip2', 'https://github.com/texastribune/queso-tools', 'https://github.com/texastribune/django-locking', 'https://github.com/texastribune/data-visuals-create', 'https://github.com/texastribune/tacobots', 'https://github.com/newscorp-ghfb/validates_timeliness','https://github.com/newscorp-ghfb/rbenv-cookbook','https://github.com/newscorp-ghfb/geogle']\n",
    "    url2 = ['https://github.com/pewresearch/pewtils', 'https://github.com/pewresearch/search_sampler', 'https://github.com/gawkermedia/kinja-post-gem', 'https://github.com/bloomberg/chef-bcpc', 'https://github.com/bloomberg/locking_resource-cookbook', 'https://github.com/bloomberg/collectd-cookbook', 'https://github.com/bloomberg/nginx-cookbook', 'https://github.com/bloomberg/consul-cluster-cookbook', 'https://github.com/bloomberg/cobbler-cookbook', 'https://github.com/bloomberg/openbfdd-cookbook', 'https://github.com/newscorp-ghfb/kaminari']\n",
    "    url3 = ['https://github.com/bloomberg/chef-bcs', 'https://github.com/bloomberg/zookeeper-cookbook', 'https://github.com/bloomberg/confd-cookbook', 'https://github.com/bloomberg/collectd_plugins-cookbook', 'https://github.com/bloomberg/kubernetes-cluster-cookbook', 'https://github.com/nytimes/nytcampfin', 'https://github.com/techcrunch/json_printer', 'https://github.com/observermedia/realgraph-listener', 'https://github.com/observermedia/django-wordpress-rest', 'https://github.com/thenextweb/passgenerator']\n",
    "    url4 = ['https://github.com/thenextweb/amp-wp', 'https://github.com/thenextweb/laravel-elasticsearch', 'https://github.com/thenextweb/slack-laravel', 'https://github.com/thenextweb/craft-3-adminbar', 'https://github.com/npr/frank', 'https://github.com/thenextweb/Embed', 'https://github.com/thenextweb/oembed', 'https://github.com/thenextweb/flatten', 'https://github.com/thenextweb/curl', 'https://github.com/npr/php-image-optim', 'https://github.com/texastribune/top10pct', 'https://github.com/texastribune/newsapps-app-kit']\n",
    "    url5 = ['https://github.com/thenextweb/cro', 'https://github.com/npr/node-randomstring', 'https://github.com/texastribune/tx_salaries', 'https://github.com/texastribune/the-dp', 'https://github.com/texastribune/tx_lege_districts', 'https://github.com/texastribune/tt_social_auth', 'https://github.com/texastribune/armstrong.core.tt_sections', 'https://github.com/texastribune/aeis', 'https://github.com/texastribune/ox-scale', 'https://github.com/texastribune/django-gistpage', 'https://github.com/newscorp-ghfb/sidekiq-throttler']\n",
    "    url6 = ['https://github.com/theatlantic/django-nested-admin', 'https://github.com/theatlantic/django-xml', 'https://github.com/theatlantic/django-select2-forms', 'https://github.com/theatlantic/django-admin-locking', 'https://github.com/texastribune/lethal-drug-tracker', 'https://github.com/texastribune/txlege-camera-status', 'https://github.com/texastribune/postcss-amp', 'https://github.com/texastribune/talk', 'https://github.com/texastribune/code-grabber', 'https://github.com/texastribune/react-external-boilerplate']\n",
    "    url7 = ['https://github.com/voxmedia/vc-ikea-minisite', 'https://github.com/voxmedia/viz-app', 'https://github.com/voxmedia/prebid.github.io', 'https://github.com/voxmedia/Transcriber', 'https://github.com/voxmedia/userstamp', 'https://github.com/voxmedia/gliss', 'https://github.com/nbcnews/octopus-vr', 'https://github.com/texastribune/donations-app', 'https://github.com/texastribune/djangocms-text-ckeditor', 'https://github.com/texastribune/newsapps-styleguide-2.0', 'https://github.com/texastribune/500', 'https://github.com/WSJ/pinpoint-editor', 'https://github.com/WSJ/ballot-tally']\n",
    "    url8 = ['https://github.com/texastribune/txlege84', 'https://github.com/texastribune/donation-builder', 'https://github.com/abcnews/scrollyteller', 'https://github.com/abcnews/odyssey-scrollyteller', 'https://github.com/abcnews/data-life', 'https://github.com/abcnews/interactive-ssm-map', 'https://github.com/ajam/chartbuilder-electron', 'https://github.com/WSJ/scroll-watcher', 'https://github.com/WSJ/two-step', 'https://github.com/texastribune/faces-of-death-row', 'https://github.com/texastribune/text-balancer', 'https://github.com/WSJ/squaire']\n",
    "    url9 = ['https://github.com/WSJ/the-meta-tag-checker', 'https://github.com/npr/nprapi-wordpress', 'https://github.com/npr/npr-one-backend-proxy-php', 'https://github.com/npr/pmp-wordpress-plugin', 'https://github.com/npr/pmp-php-sdk', 'https://github.com/npr/pmp-drupal-plugin', 'https://github.com/npr/zaphpa', 'https://github.com/npr/silverstripe-opauth', 'https://github.com/npr/Slim']\n",
    "    urls= url+url2+url3+url4+url5+url6+url7+url8+url9\n",
    "    \n",
    "    file = 'gitMDs.json'\n",
    "    if os.path.isfile(file):\n",
    "        gitmds = pd.read_json(file)\n",
    "        return gitmds\n",
    "    \n",
    "    else:\n",
    "        github = []\n",
    "        for url in urls:\n",
    "            response = get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "            code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "            dicob = {'body':body, 'top_code':code}\n",
    "            github.append(dicob)\n",
    "            time.sleep(2)\n",
    "\n",
    "        gitmds = pd.DataFrame(github)\n",
    "        gitmds.to_json('gitMDs.json')\n",
    "        return gitmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gitMDs = get_gitmds()\n",
    "gitMDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def basic_body_clean(somestring):\n",
    "    '''\n",
    "    Takes in body text of a README and performs a basic clean by first converting it to all lower case letters,\n",
    "    then normalizes the encoding, and removes any character that isn't a letter, number, or a space.\n",
    "    Returns the result.\n",
    "    '''\n",
    "    basic = somestring.lower()\n",
    "    basic = unicodedata.normalize('NFKD', basic).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    basic = re.sub(r\"[^a-z0-9'\\s]\", '', basic)\n",
    "    return basic\n",
    "\n",
    "def basic_code_clean(somestring):\n",
    "    '''\n",
    "    Takes in the code text and performs a basic clean by first converting it to all lower case letters,\n",
    "    then normalizes the encoding, and finally removes any character that isn't a letter, number, period (.), or a space.\n",
    "    Keeps the period because the code block text is expressed as a percentage with a period\n",
    "    Returns the result.\n",
    "    '''\n",
    "    basic = somestring.lower()\n",
    "    basic = unicodedata.normalize('NFKD', basic).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    basic = re.sub(r\"[^a-z0-9'\\s.]\", '', basic)\n",
    "    return basic\n",
    "\n",
    "def tokenize(somestring):\n",
    "    '''\n",
    "    Creates a tokenizer object to tokenize the given string and then returns the tokenized string\n",
    "    '''\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    tokened = tokenizer.tokenize(somestring, return_str=True)    \n",
    "    return tokened\n",
    "\n",
    "def lemmatize(somestring):\n",
    "    '''\n",
    "    Creates a lemmatize object and then uses it to lemmatize the provided string. Returns the lemmatized string \n",
    "    '''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in somestring.split()]\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized\n",
    "\n",
    "def remove_stopwords(string, keep_words=['no', 'not'], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, removes stop_words from the string, and then returns the results.\n",
    "    The fuction also allows for optional arugments keep_words and exclud_words to modify the stop word list\n",
    "    * keep_words - a list of words to remove from the standard english stopwords list from nltk.corpus i.e. no or not\n",
    "    * exclude_words - a list of words to add to the standard english stopwords list from nltk.corpus \n",
    "    i.e. ['data', 'science'] to the remove both words when dealing with articles only about data science\n",
    "    * By default, keep_words includes no and not\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    # Remove 'keep_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(keep_words)\n",
    "    # Add in 'exclude_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(exclude_words))\n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    return string_without_stopwords\n",
    "\n",
    "def prep_gitMDs():\n",
    "    '''\n",
    "    Uses the above helper on the gitMDs repo url list to creates to\n",
    "    * Applies a basic_body_clean, tokenizizatize, removestop_words, AND lemmatizes fuctions to the readme body text\n",
    "    and returns the output as df['clean'] \n",
    "    * Applies the basic_code_clean, tokenizizatize, and removestop_words fuctions to the top_code and returns it as df['top_code_cleaned]\n",
    "    * Splits df['top_code_cleaned] into two columns df['top_code_cleaned'] and df['top_percentage_cleaned'] extended\n",
    "    * returns the df\n",
    "    '''    \n",
    "    gitMDs = pd.DataFrame(get_gitmds())\n",
    "    gitMDs['clean'] = gitMDs['body'].apply(basic_body_clean).apply(tokenize).apply(remove_stopwords).apply(lemmatize)\n",
    "    gitMDs['top_code_clean'] = gitMDs['top_code'].apply(basic_code_clean).apply(tokenize).apply(remove_stopwords)\n",
    "    gitMDs[['top_code_clean', 'percentage']] = gitMDs['top_code_clean'].str.split(\" \",expand=True)\n",
    "    gitMDs['percentage'] = pd.to_numeric(gitMDs['percentage'])\n",
    "    return gitMDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gitMDs = prep_gitMDs()\n",
    "gitMDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gitMDs['top_code_clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series objects for each top_code_clean that is a string of words joined on spaces to make it 1 continious string  \n",
    "python_words = ' '.join(gitMDs[gitMDs.top_code_clean=='python'].clean)\n",
    "javascript_words = ' '.join(gitMDs[gitMDs.top_code_clean=='javascript'].clean)\n",
    "ruby_words = ' '.join(gitMDs[gitMDs.top_code_clean=='ruby'].clean)\n",
    "html_words = ' '.join(gitMDs[gitMDs.top_code_clean=='html'].clean)\n",
    "php_words = ' '.join(gitMDs[gitMDs.top_code_clean=='php'].clean)\n",
    "all_words = ' '.join(gitMDs.clean)\n",
    "\n",
    "python_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_words = re.sub(r'\\s.\\s', '', python_words)\n",
    "javascript_words = re.sub(r'\\s.\\s', '', javascript_words)\n",
    "ruby_words = re.sub(r'\\s.\\s', '', ruby_words)\n",
    "html_words = re.sub(r'\\s.\\s', '', html_words)\n",
    "php_words = re.sub(r'\\s.\\s', '', php_words)\n",
    "all_words = re.sub(r'\\s.\\s', '', all_words)\n",
    "\n",
    "python_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each topic find out how many times each word happens and put that into a topic_freq obj.\n",
    "all_freq = pd.Series(all_words.split()).value_counts()\n",
    "python_freq = pd.Series(python_words.split()).value_counts()\n",
    "javascript_freq = pd.Series(javascript_words.split()).value_counts()\n",
    "ruby_freq = pd.Series(ruby_words.split()).value_counts()\n",
    "html_freq = pd.Series(html_words.split()).value_counts()\n",
    "php_freq = pd.Series(php_words.split()).value_counts()\n",
    "\n",
    "\n",
    "python_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the series together into a single data frame to see the word count across all topics\n",
    "word_counts = (pd.concat([all_freq, python_freq, javascript_freq, ruby_freq, html_freq, php_freq], axis=1, sort=True)\n",
    "               .set_axis(['all', 'python', 'javascript', 'ruby', 'html', 'php'], axis=1, inplace=False)\n",
    "               .fillna(0)\n",
    "               .apply(lambda s: s.astype(int))\n",
    "              )\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values(by='python', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts[word_counts.html<5].sort_values(by='python', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the percentage topic percentage make up of each word\n",
    "plt.figure(figsize=(20,14))\n",
    "(word_counts.assign(p_python = word_counts.python/word_counts['all'], \n",
    "                   p_javascript = word_counts.javascript/word_counts['all'],\n",
    "                   p_ruby = word_counts.ruby/word_counts['all'],\n",
    "                   p_html = word_counts.html/word_counts['all'],\n",
    "                   p_php = word_counts.php/word_counts['all'])\n",
    " .sort_values(by='all')[['p_python', 'p_javascript', 'p_ruby', 'p_html', 'p_php']]\n",
    " .tail(20)\n",
    " .sort_values(by='p_python')\n",
    " .plot.barh(stacked=True)\n",
    ")\n",
    "\n",
    "plt.title(\"Proportions of the Top 20 Words Across Code Languages\")\n",
    "plt.legend(bbox_to_anchor=(1.35, 1),borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repos = ['https://github.com/search?l=JavaScript&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=20&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=20&q=stars%3A%3E0&s=stars&type=Repositories']\n",
    "\n",
    "\n",
    "base_url = \"https://github.com/\"\n",
    "to_scrape = []\n",
    "for url in urls: \n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.findAll('a', class_='v-align-middle')\n",
    "    time.sleep(3)\n",
    "    for link in links:\n",
    "        to_scrape.append(base_url+link.text)\n",
    "\n",
    "len(to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)     \n",
    "github = []\n",
    "for url in urls:\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "    code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "    dicob = {'body':body, 'top_code':code}\n",
    "    github.append(dicob)\n",
    "    time.sleep(2)\n",
    "\n",
    "gitmds = pd.DataFrame(github)\n",
    "gitmds.to_json('gitMDs.json')\n",
    "gitmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gitmds():     \n",
    "    '''\n",
    "    * Creates a list of urls from the top 200 most starred repos of both Python and Javascript code\n",
    "    * Then for each url it scrapes the text from their readmes and code blocks to generate a json dictionary file \n",
    "    that looks like {\"body\":text from the readme, \"top_code\":the first entry from the code block}.\n",
    "    * File name generated is gitMDs.json\n",
    "    * If file exists it will read the file into a dataframe\n",
    "    * If the file does not exist it will create the file (outlined above) and will return a dataframe of the file\n",
    "\n",
    "    Note - The initial file creation time is ~4min and 30secs. The file has been included in this repo due to that.\n",
    "    '''\n",
    "    file = 'gitMDs.json'\n",
    "    if os.path.isfile(file):\n",
    "        gitmds = pd.read_json(file)\n",
    "        return gitmds\n",
    "    \n",
    "    else:\n",
    "        repos = ['https://github.com/search?l=JavaScript&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=JavaScript&p=20&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "        'https://github.com/search?l=Python&p=20&q=stars%3A%3E0&s=stars&type=Repositories']\n",
    "        \n",
    "        base_url = \"https://github.com/\"\n",
    "        urls = []\n",
    "        for repo in repos: \n",
    "            response = get(repo)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            links = soup.findAll('a', class_='v-align-middle')\n",
    "            time.sleep(3)\n",
    "            for link in links:\n",
    "                urls.append(base_url+link.text)  \n",
    "                \n",
    "        time.sleep(3)     \n",
    "        github = []\n",
    "        for url in urls:\n",
    "            response = get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser') \n",
    "            try:\n",
    "                body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "            except AttributeError:\n",
    "                continue\n",
    "            code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "            dicob = {'body':body, 'top_code':code}\n",
    "            github.append(dicob)\n",
    "            time.sleep(2)\n",
    "\n",
    "        gitmds = pd.DataFrame(github)\n",
    "        gitmds.to_json('gitMDs.json')\n",
    "        return gitmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "        x = float(row['Close Ask']) - float(row['Close Bid'])\n",
    "    except ValueError:\n",
    "        continue\n",
    "    else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-59b6d543c658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgitMDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_gitmds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgitMDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-71f5a123b90e>\u001b[0m in \u001b[0;36mget_gitmds\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'markdown-body entry-content container-lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'd-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mdicob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'top_code'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "gitMDs = get_gitmds()\n",
    "gitMDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repo links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = ['https://github.com/search?l=JavaScript&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=JavaScript&p=20&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=2&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=3&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=4&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=5&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=6&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=7&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=8&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=9&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=10&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=11&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=12&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=13&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=14&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=15&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=16&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=17&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=18&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=19&q=stars%3A%3E0&s=stars&type=Repositories',\n",
    "'https://github.com/search?l=Python&p=20&q=stars%3A%3E0&s=stars&type=Repositories']\n",
    "\n",
    "base_url = \"https://github.com/\"\n",
    "urls = []\n",
    "for repo in repos: \n",
    "    response = get(repo)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.findAll('a', class_='v-align-middle')\n",
    "    time.sleep(2)\n",
    "    for link in links:\n",
    "        urls.append(base_url+link.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "github = []\n",
    "for url in urls:\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser') \n",
    "    try:\n",
    "        body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "    dicob = {'body':body, 'top_code':code}\n",
    "    github.append(dicob)\n",
    "    time.sleep(2)\n",
    "            \n",
    "gitmds = pd.DataFrame(github)\n",
    "gitmds.to_json('gitMDs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>top_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...</td>\n",
       "      <td>\\n\\nJavaScript\\n91.3%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...</td>\n",
       "      <td>\\n\\nJavaScript\\n97.7%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>React ·    \\nReact is a JavaScript library for...</td>\n",
       "      <td>\\n\\nJavaScript\\n95.0%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...</td>\n",
       "      <td>\\n\\nJavaScript\\n46.7%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb JavaScript Style Guide() {\\nA mostly re...</td>\n",
       "      <td>\\n\\nJavaScript\\n100.0%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nA very simple framework for state-...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>The GAN Zoo\\n\\nEvery week, new GAN papers are ...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Fast Style Transfer in TensorFlow\\nAdd styles ...</td>\n",
       "      <td>\\n\\nPython\\n99.3%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>\\nNeural Doodle\\n\\nUse a deep neural network t...</td>\n",
       "      <td>\\n\\nPython\\n96.3%\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>\\n\\n\\n\\nTFLearn: Deep learning library featuri...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    \\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...   \n",
       "1    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...   \n",
       "2    React ·    \\nReact is a JavaScript library for...   \n",
       "3    \\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...   \n",
       "4    Airbnb JavaScript Style Guide() {\\nA mostly re...   \n",
       "..                                                 ...   \n",
       "175  \\n\\n\\n\\n\\n\\nA very simple framework for state-...   \n",
       "176  The GAN Zoo\\n\\nEvery week, new GAN papers are ...   \n",
       "177  Fast Style Transfer in TensorFlow\\nAdd styles ...   \n",
       "178  \\nNeural Doodle\\n\\nUse a deep neural network t...   \n",
       "179  \\n\\n\\n\\nTFLearn: Deep learning library featuri...   \n",
       "\n",
       "                     top_code  \n",
       "0     \\n\\nJavaScript\\n91.3%\\n  \n",
       "1     \\n\\nJavaScript\\n97.7%\\n  \n",
       "2     \\n\\nJavaScript\\n95.0%\\n  \n",
       "3     \\n\\nJavaScript\\n46.7%\\n  \n",
       "4    \\n\\nJavaScript\\n100.0%\\n  \n",
       "..                        ...  \n",
       "175      \\n\\nPython\\n100.0%\\n  \n",
       "176      \\n\\nPython\\n100.0%\\n  \n",
       "177       \\n\\nPython\\n99.3%\\n  \n",
       "178       \\n\\nPython\\n96.3%\\n  \n",
       "179      \\n\\nPython\\n100.0%\\n  \n",
       "\n",
       "[180 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gitmds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'一些非常有趣的python爬虫例子,对新手比较友好\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n项目简介\\n一些常见的网站爬虫例子，代码通用性较高，时效性较久。项目代码对新手比较友好，尽量用简单的python代码，并配有大量注释。\\n\\n\\n如何下载\\n没有或不懂如何设置代理的中国用户, 可跳转至镜像仓库码云Gitee进行下载, 以便获得较快的下载速度。\\n\\n\\n1.淘宝模拟登录\\n使用教程\\n\\n点击这里下载下载chrome浏览器\\n查看chrome浏览器的版本号，点击这里下载对应版本号的chromedriver驱动\\npip安装下列包\\n\\n pip install selenium\\n\\n\\n点击这里登录微博，并通过微博绑定淘宝账号密码\\n在main中填写chromedriver的绝对路径\\n在main中填写微博账号密码\\n\\n#改成你的chromedriver的完整路径地址\\nchromedriver_path = \"/Users/bird/Desktop/chromedriver.exe\" \\n#改成你的微博账号\\nweibo_username = \"改成你的微博账号\"\\n#改成你的微博密码\\nweibo_password = \"改成你的微博密码\"\\n演示图片\\n\\n\\n\\n2.天猫商品数据爬虫\\n使用教程\\n\\n点击这里下载下载chrome浏览器\\n查看chrome浏览器的版本号，点击这里下载对应版本号的chromedriver驱动\\npip安装下列包\\n\\n pip install selenium\\n pip install pyquery\\n\\n\\n点击这里登录微博，并通过微博绑定淘宝账号密码\\n在main中填写chromedriver的绝对路径\\n在main中填写微博账号密码\\n\\n#改成你的chromedriver的完整路径地址\\nchromedriver_path = \"/Users/bird/Desktop/chromedriver.exe\" \\n#改成你的微博账号\\nweibo_username = \"改成你的微博账号\"\\n#改成你的微博密码\\nweibo_password = \"改成你的微博密码\"\\n演示图片\\n\\n\\n\\n\\n3.爬取淘宝我已购买的宝贝数据\\n使用教程\\n\\n点击这里下载下载chrome浏览器\\n查看chrome浏览器的版本号，点击这里下载对应版本号的chromedriver驱动\\npip安装下列包\\n\\n pip install selenium\\n pip install pyquery\\n\\n\\n点击这里登录微博，并通过微博绑定淘宝账号密码\\n在main中填写chromedriver的绝对路径\\n在main中填写微博账号密码\\n\\n#改成你的chromedriver的完整路径地址\\nchromedriver_path = \"/Users/bird/Desktop/chromedriver.exe\" \\n#改成你的微博账号\\nweibo_username = \"改成你的微博账号\"\\n#改成你的微博密码\\nweibo_password = \"改成你的微博密码\"\\n演示图片\\n\\n\\n\\n\\n4.每天不同时间段通过微信发消息提醒女友\\n简介\\n有时候，你很想关心她，但是你太忙了，以至于她一直抱怨，觉得你不够关心她。你暗自下决心，下次一定要准时发消息给她，哪怕是几句话，可是你又忘记了。你觉得自己很委屈😭，但是她又觉得你不负责。\\n\\n现在，再不用担心了，用python就可以给女友定时发提示消息了，而且不会漏过每一个关键时刻，每天早上起床、中午吃饭、晚上吃饭、晚上睡觉，都会准时发消息给她了，而且还可以让她学习英语单词哦！\\n\\n在生日来临之时，自动发祝福语。在节日来临之时，比如**三八妇女节、女神节、情人节、春节、圣诞节**，自动发问候语哦，再也不用担心他说你没有仪式感了😀\\n\\n最重要的时候，实时可以知道女友的情感情绪指数哦，再也不用担心女友莫名其妙生气了。\\n使用教程\\n\\npip安装下列包\\n\\n\\n pip install wxpy\\n pip install requests\\n\\n\\n设置以下内容\\n\\n\\n 设置config.ini相关信息\\n\\n演示图片\\n\\n\\n\\n\\n5.爬取5K分辨率超清唯美壁纸\\n简介\\n壁纸的选择其实很大程度上能看出电脑主人的内心世界，有的人喜欢风景，有的人喜欢星空，有的人喜欢美女，有的人喜欢动物。然而，终究有一天你已经产生审美疲劳了，但你下定决定要换壁纸的时候，又发现网上的壁纸要么分辨率低，要么带有水印。\\n\\n这里有一款Mac下的小清新壁纸神器Pap.er，可能是Mac下最好的壁纸软件，自带5K超清分辨率壁纸，富有多种类型壁纸，当我们想在Windows或者Linux下使用的时候，就可以考虑将5K超清分辨率壁纸爬取下来。\\n使用教程\\n\\n确保以下库均已安装：\\n\\n# 如果没有安装，请使用pip install module安装\\nimport requests\\nimport filetype\\nimport os\\nimport json\\nfrom contextlib import closing\\n演示图片\\n\\n\\n\\n\\n6.爬取豆瓣排行榜电影数据(含GUI界面版)\\n简介\\n这个项目源于大三某课程设计。平常经常需要搜索一些电影，但是不知道哪些评分高且评价人数多的电影。为了方便使用，就将原来的项目重新改写了。当做是对爬虫技术、可视化技术的实践了。主要是通过从排行榜和从影片关键词两种方式爬取电影数据。\\n使用教程\\n\\n打开http://chromedriver.storage.googleapis.com/index.html，根据自己的操作系统下载对应的chromedriver\\n打开当前面目录下的**getMovieInRankingList.py**，定位到第59行，将executable_path=/Users/bird/Desktop/chromedriver.exe修改成你自己的chromedriver路径\\n打开pycharm，依次安装以下包\\n\\n\\npip install Pillow\\npip install selenium\\n\\n演示图片\\n\\n\\n包含功能\\n\\n 根据关键字搜索电影\\n 根据排行榜(TOP250)搜索电影\\n 显示IMDB评分及其他基本信息\\n 提供多个在线视频站点，无需vip\\n 提供多个云盘站点搜索该视频，以便保存到云盘\\n 提供多个站点下载该视频\\n 等待更新\\n\\n存在问题\\n目前没有加入反爬虫策略，如果运行出现403 forbidden提示，则说明暂时被禁止，解决方式如下：\\n\\n加入cookies\\n采用随机延时方式\\n采用IP代理池方式(较不稳定)\\n\\n\\n\\n7.多线程+代理池爬取天天基金网、股票数据(无需使用爬虫框架)\\n简介\\n提到爬虫，大部分人都会想到使用Scrapy工具，但是仅仅停留在会使用的阶段。为了增加对爬虫机制的理解，我们可以手动实现多线程的爬虫过程，同时，引入IP代理池进行基本的反爬操作。\\n本次使用天天基金网进行爬虫，该网站具有反爬机制，同时数量足够大，多线程效果较为明显。\\n技术路线\\n\\nIP代理池\\n多线程\\n爬虫与反爬\\n\\n数据格式\\n000056,建信消费升级混合,2019-03-26,1.7740,1.7914,0.98,2019-03-27 15:00\\n000031,华夏复兴混合,2019-03-26,1.5650,1.5709,0.38,2019-03-27 15:00\\n000048,华夏双债增强债券C,2019-03-26,1.2230,1.2236,0.05,2019-03-27 15:00\\n000008,嘉实中证500ETF联接A,2019-03-26,1.4417,1.4552,0.93,2019-03-27 15:00\\n000024,大摩双利增强债券A,2019-03-26,1.1670,1.1674,0.04,2019-03-27 15:00\\n000054,鹏华双债增利债券,2019-03-26,1.1697,1.1693,-0.03,2019-03-27 15:00\\n000016,华夏纯债债券C,2019-03-26,1.1790,1.1793,0.03,2019-03-27 15:00\\n功能截图\\n\\n配置说明\\n\\t# 确保安装以下库，如果没有，请在python3环境下执行pip install 模块名\\n\\timport requests\\n\\timport random\\n\\timport re\\n\\timport queue\\n\\timport threading\\n\\timport csv\\n\\timport json\\n\\n\\n8.一键生成微信个人专属数据报告(了解你的微信社交历史))\\n简介\\n你是否想过生成一份属于你的微信个人数据报告，了解你的微信社交历史。现在，我们基于python对微信好友进行全方位数据分析，包括：昵称、性别、年龄、地区、备注名、个性签名、头像、群聊、公众号等。\\n其中，在分析好友类型方面，主要统计出你的陌生人、星标好友、不让他看我的朋友圈的好友、不看他的朋友圈的好友数据。在分析地区方面，主要统计所有好友在全国的分布以及对好友数最多的省份进行进一步分析。在其他方面，统计出你的好友性别比例、猜出你最亲密的好友，分析你的特殊好友，找出与你所在共同群聊数最多的好友数据，对你的好友个性签名进行分析，对你的好友头像进行分析，并进一步检测出使用真人头像的好友数据。\\n目前网上关于这方面的数据分析文章比较多，但是运行起来比较麻烦，而本程序的运行十分简单，只需要扫码登录一步操作即可。\\n功能截图\\n\\n\\n\\n\\n\\n\\n\\n如何运行\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt\\n# 开始运行\\npython generate_wx_data.py\\n如何打包成二进制可执行文件\\n# 安装pyinstaller\\npip install pyinstaller\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt\\n# 更新 setuptools\\npip install --upgrade setuptools\\n# 开始打包\\npyinstaller generate_wx_data.py\\n9.一键生成QQ个人历史报告\\n简介\\n近几年，由于微信的流行，大部分人不再频繁使用QQ，所以我们对于自己的QQ数据并不是特别了解。我相信，如果能够生成一份属于自己的QQ历史报告，那将是无比开心的一件事。\\n目前网上关于QQ的数据分析工具较少，原因是QQ相关接口比较复杂。而本程序的运行十分简单，具有良好的用户交互界面，只需要扫码登录一步操作即可。\\n目前本程序获取的数据包括：QQ详细数据、手机在线时间、非隐身状态下在线时间、QQ活跃时间、单向好友数量、QQ财产分析、群聊分析、过去一年我退出的群聊数据、退去一个月我删除的好友数据、所有代付信息、我最在意的人以及最在意我的人。由于相关的数据接口有访问限制，所以本程序并没有对QQ好友进行分析。\\n功能截图\\n\\n\\n\\n\\n如何运行\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt\\n# 开始运行\\npython main.py\\n\\n\\n10.一键生成个人微信朋友圈数据电子书\\n简介\\n微信朋友圈保留着你的数据，它留住了美好的回忆，记录了我们成长的点点滴滴。发朋友圈从某种意义上来讲是在记录生活，感受生活，并从中看到了每个人每一步的成长。\\n这么一份珍贵的记忆，何不将它保存下来呢？只需一杯咖啡的时间，即可一键打印你的朋友圈。它可以是纸质书，也可以是电子书，可以长久保存，比洗照片好，又有时间足迹记忆。\\n\\n这本书，可以用来：\\n送给孩子的生日礼物\\n送给伴侣的生日礼物\\n送给未来的自己\\n……\\n\\n现在，你可以选择打印电子书或者纸质书。打印纸质书的话，可以找第三方机构花钱购买；打印电子书的话，我们完全可以自己动手生成，这可以省下一笔不小的开支。\\n功能截图\\n在开始写代码思路之前，我们先看看最终生成的效果。\\n电子书效果(图片引用自出书啦)\\n\\n\\n纸质书效果(图片引用自心书)\\n\\n如何运行\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt\\n# 开始运行\\npython main.py\\n\\n\\n11.一键分析你的上网行为(web页面可视化)\\n简介\\n想看看你最近一年都在干嘛？看看你平时上网是在摸鱼还是认真工作？想写年度汇报总结，但是苦于没有数据？现在，它来了。\\n这是一个能让你了解自己的浏览历史的Chrome浏览历史记录分析程序，他适用于Chrome浏览器或者以Chromium为内核的浏览器。目前国内大部分浏览器均是以Chromium为内核的浏览器，所以基本上都可以使用。但是不支持以下浏览器：IE浏览器、Firefox浏览器、Safari浏览器。\\n在该页面中你将可以查看有关自己在过去的时间里所访问浏览的域名、URL以及忙碌天数的前十排名以及相关的数据图表。\\n功能截图\\n在开始写代码思路之前，我们先看看最终生成的效果。\\n\\n如何运行\\n在线演示程序:http://39.106.118.77:8090(普通服务器，勿测压)\\n运行本程序十分简单，只需要按照以下命令即可运行：\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt\\n# 开始运行\\npython app.py\\n\\n# 运行成功后，通过浏览器打开http://localhost:8090\\n\\n\\n12.一键导出微信读书的书籍和笔记\\n\\n本项目基于@arry-lee的项目wereader修改而来，感谢原作者提供的源代码。\\n\\n\\n简介\\n全民阅读的时代已经来临，目前使用读书软件的用户数2.1亿，日活跃用户超过500万，其中19-35岁年轻用户占比超过60%，本科及以上学历用户占比高达80%，北上广深及其他省会城市/直辖市用户占比超过80%。本人习惯使用微信读书，为了方便整理书籍和导出笔记，便开发了这个小工具。\\n功能截图\\n在开始写代码思路之前，我们先看看最终生成的效果。\\n\\n\\n\\n如何运行\\n# 跳转到当前目录\\ncd 目录名\\n# 先卸载依赖库\\npip uninstall -y -r requirement.txt\\n# 再重新安装依赖库\\npip install -r requirement.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\\n# 开始运行\\npython pyqt_gui.py\\n\\n\\n补充\\n项目持续更新，欢迎您star本项目\\n\\n\\nLicense\\nThe MIT License (MIT)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/shengqiangzhang/examples-of-web-crawlers'\n",
    "\n",
    "response = get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>top_code</th>\n",
       "      <th>clean</th>\n",
       "      <th>top_code_clean</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...</td>\n",
       "      <td>\\n\\nJavaScript\\n91.3%\\n</td>\n",
       "      <td>freecodecamporg ' opensource codebase curricul...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>91.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...</td>\n",
       "      <td>\\n\\nJavaScript\\n97.7%\\n</td>\n",
       "      <td>supporting vuejs vuejs mitlicensed open source...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>97.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>React ·    \\nReact is a JavaScript library for...</td>\n",
       "      <td>\\n\\nJavaScript\\n95.0%\\n</td>\n",
       "      <td>react react javascript library building user i...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...</td>\n",
       "      <td>\\n\\nJavaScript\\n46.7%\\n</td>\n",
       "      <td>bootstrap sleek intuitive powerful frontend fr...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb JavaScript Style Guide() {\\nA mostly re...</td>\n",
       "      <td>\\n\\nJavaScript\\n100.0%\\n</td>\n",
       "      <td>airbnb javascript style guide mostly reasonabl...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\nA very simple framework for state-...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "      <td>simple framework stateoftheart nlp developed h...</td>\n",
       "      <td>python</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>The GAN Zoo\\n\\nEvery week, new GAN papers are ...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "      <td>gan zoo every week new gan paper coming ' hard...</td>\n",
       "      <td>python</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Fast Style Transfer in TensorFlow\\nAdd styles ...</td>\n",
       "      <td>\\n\\nPython\\n99.3%\\n</td>\n",
       "      <td>fast style transfer tensorflow add style famou...</td>\n",
       "      <td>python</td>\n",
       "      <td>99.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>\\nNeural Doodle\\n\\nUse a deep neural network t...</td>\n",
       "      <td>\\n\\nPython\\n96.3%\\n</td>\n",
       "      <td>neural doodle use deep neural network borrow s...</td>\n",
       "      <td>python</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>\\n\\n\\n\\nTFLearn: Deep learning library featuri...</td>\n",
       "      <td>\\n\\nPython\\n100.0%\\n</td>\n",
       "      <td>tflearn deep learning library featuring higher...</td>\n",
       "      <td>python</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  \\\n",
       "0    \\n\\n\\n\\n\\nfreeCodeCamp.org's open-source codeb...   \n",
       "1    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupporting Vue.js\\nVue.j...   \n",
       "2    React ·    \\nReact is a JavaScript library for...   \n",
       "3    \\n\\n\\n\\n\\nBootstrap\\n\\n  Sleek, intuitive, and...   \n",
       "4    Airbnb JavaScript Style Guide() {\\nA mostly re...   \n",
       "..                                                 ...   \n",
       "175  \\n\\n\\n\\n\\n\\nA very simple framework for state-...   \n",
       "176  The GAN Zoo\\n\\nEvery week, new GAN papers are ...   \n",
       "177  Fast Style Transfer in TensorFlow\\nAdd styles ...   \n",
       "178  \\nNeural Doodle\\n\\nUse a deep neural network t...   \n",
       "179  \\n\\n\\n\\nTFLearn: Deep learning library featuri...   \n",
       "\n",
       "                     top_code  \\\n",
       "0     \\n\\nJavaScript\\n91.3%\\n   \n",
       "1     \\n\\nJavaScript\\n97.7%\\n   \n",
       "2     \\n\\nJavaScript\\n95.0%\\n   \n",
       "3     \\n\\nJavaScript\\n46.7%\\n   \n",
       "4    \\n\\nJavaScript\\n100.0%\\n   \n",
       "..                        ...   \n",
       "175      \\n\\nPython\\n100.0%\\n   \n",
       "176      \\n\\nPython\\n100.0%\\n   \n",
       "177       \\n\\nPython\\n99.3%\\n   \n",
       "178       \\n\\nPython\\n96.3%\\n   \n",
       "179      \\n\\nPython\\n100.0%\\n   \n",
       "\n",
       "                                                 clean top_code_clean  \\\n",
       "0    freecodecamporg ' opensource codebase curricul...     javascript   \n",
       "1    supporting vuejs vuejs mitlicensed open source...     javascript   \n",
       "2    react react javascript library building user i...     javascript   \n",
       "3    bootstrap sleek intuitive powerful frontend fr...     javascript   \n",
       "4    airbnb javascript style guide mostly reasonabl...     javascript   \n",
       "..                                                 ...            ...   \n",
       "175  simple framework stateoftheart nlp developed h...         python   \n",
       "176  gan zoo every week new gan paper coming ' hard...         python   \n",
       "177  fast style transfer tensorflow add style famou...         python   \n",
       "178  neural doodle use deep neural network borrow s...         python   \n",
       "179  tflearn deep learning library featuring higher...         python   \n",
       "\n",
       "     percentage  \n",
       "0          91.3  \n",
       "1          97.7  \n",
       "2          95.0  \n",
       "3          46.7  \n",
       "4         100.0  \n",
       "..          ...  \n",
       "175       100.0  \n",
       "176       100.0  \n",
       "177        99.3  \n",
       "178        96.3  \n",
       "179       100.0  \n",
       "\n",
       "[180 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gitmds['clean'] = gitmds['body'].apply(basic_body_clean).apply(tokenize).apply(remove_stopwords).apply(lemmatize)\n",
    "gitmds['top_code_clean'] = gitmds['top_code'].apply(basic_code_clean).apply(tokenize).apply(remove_stopwords)\n",
    "gitmds[['top_code_clean', 'percentage']] = gitmds['top_code_clean'].str.split(\" \",expand=True)\n",
    "gitmds['percentage'] = pd.to_numeric(gitmds['percentage'])\n",
    "gitmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "python        90\n",
       "javascript    90\n",
       "Name: top_code_clean, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gitmds['top_code_clean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
