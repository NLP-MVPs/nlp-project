{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ['https://github.com/pewresearch/pewanalytics', 'https://github.com/texastribune/scuole', 'https://github.com/texastribune/thermometer', 'https://github.com/texastribune/walls', 'https://github.com/texastribune/geoip2', 'https://github.com/texastribune/queso-tools', 'https://github.com/texastribune/django-locking', 'https://github.com/texastribune/data-visuals-create', 'https://github.com/texastribune/tacobots', 'https://github.com/newscorp-ghfb/validates_timeliness','https://github.com/newscorp-ghfb/rbenv-cookbook','https://github.com/newscorp-ghfb/geogle']\n",
    "\n",
    "url2 = ['https://github.com/pewresearch/pewtils', 'https://github.com/pewresearch/search_sampler', 'https://github.com/gawkermedia/kinja-post-gem', 'https://github.com/bloomberg/chef-bcpc', 'https://github.com/bloomberg/locking_resource-cookbook', 'https://github.com/bloomberg/collectd-cookbook', 'https://github.com/bloomberg/nginx-cookbook', 'https://github.com/bloomberg/consul-cluster-cookbook', 'https://github.com/bloomberg/cobbler-cookbook', 'https://github.com/bloomberg/openbfdd-cookbook', 'https://github.com/newscorp-ghfb/kaminari']\n",
    "\n",
    "url3 = ['https://github.com/bloomberg/chef-bcs', 'https://github.com/bloomberg/zookeeper-cookbook', 'https://github.com/bloomberg/confd-cookbook', 'https://github.com/bloomberg/collectd_plugins-cookbook', 'https://github.com/bloomberg/kubernetes-cluster-cookbook', 'https://github.com/techcrunch/ey-cloud-recipes', 'https://github.com/techcrunch/json_printer', 'https://github.com/observermedia/realgraph-listener', 'https://github.com/observermedia/django-wordpress-rest', 'https://github.com/thenextweb/passgenerator']\n",
    "\n",
    "url4 = ['https://github.com/thenextweb/amp-wp', 'https://github.com/thenextweb/laravel-elasticsearch', 'https://github.com/thenextweb/slack-laravel', 'https://github.com/thenextweb/craft-3-adminbar', 'https://github.com/thenextweb/TNW-Social-Count', 'https://github.com/thenextweb/Embed', 'https://github.com/thenextweb/oembed', 'https://github.com/thenextweb/flatten', 'https://github.com/thenextweb/curl', 'https://github.com/thenextweb/URLResolver.php', 'https://github.com/texastribune/top10pct', 'https://github.com/texastribune/newsapps-app-kit']\n",
    "\n",
    "url5 = ['https://github.com/thenextweb/cro', 'https://github.com/thenextweb/jQuery-Search', 'https://github.com/texastribune/tx_salaries', 'https://github.com/texastribune/the-dp', 'https://github.com/texastribune/tx_lege_districts', 'https://github.com/texastribune/tt_social_auth', 'https://github.com/texastribune/armstrong.core.tt_sections', 'https://github.com/texastribune/aeis', 'https://github.com/texastribune/ox-scale', 'https://github.com/texastribune/django-gistpage', 'https://github.com/newscorp-ghfb/sidekiq-throttler']\n",
    "\n",
    "url6 = ['https://github.com/theatlantic/django-nested-admin', 'https://github.com/theatlantic/django-xml', 'https://github.com/theatlantic/django-select2-forms', 'https://github.com/theatlantic/django-admin-locking', 'https://github.com/texastribune/lethal-drug-tracker', 'https://github.com/texastribune/txlege-camera-status', 'https://github.com/texastribune/postcss-amp', 'https://github.com/texastribune/talk', 'https://github.com/texastribune/code-grabber', 'https://github.com/texastribune/react-external-boilerplate']\n",
    "\n",
    "url7 = ['https://github.com/voxmedia/vc-ikea-minisite', 'https://github.com/voxmedia/viz-app', 'https://github.com/voxmedia/prebid.github.io', 'https://github.com/voxmedia/Transcriber', 'https://github.com/voxmedia/userstamp', 'https://github.com/voxmedia/gliss', 'https://github.com/nbcnews/octopus-vr', 'https://github.com/texastribune/donations-app', 'https://github.com/texastribune/djangocms-text-ckeditor', 'https://github.com/texastribune/newsapps-styleguide-2.0', 'https://github.com/texastribune/500', 'https://github.com/WSJ/pinpoint-editor', 'https://github.com/WSJ/ballot-tally']\n",
    "\n",
    "url8 = ['https://github.com/texastribune/txlege84', 'https://github.com/texastribune/donation-builder', 'https://github.com/abcnews/scrollyteller', 'https://github.com/abcnews/odyssey-scrollyteller', 'https://github.com/abcnews/data-life', 'https://github.com/abcnews/interactive-ssm-map', 'https://github.com/ajam/chartbuilder-electron', 'https://github.com/WSJ/scroll-watcher', 'https://github.com/WSJ/two-step', 'https://github.com/texastribune/faces-of-death-row', 'https://github.com/texastribune/text-balancer', 'https://github.com/WSJ/squaire']\n",
    "\n",
    "url9 = ['https://github.com/WSJ/the-meta-tag-checker', 'https://github.com/npr/nprapi-wordpress', 'https://github.com/npr/npr-one-backend-proxy-php', 'https://github.com/npr/pmp-wordpress-plugin', 'https://github.com/npr/pmp-php-sdk', 'https://github.com/npr/pmp-drupal-plugin', 'https://github.com/npr/zaphpa', 'https://github.com/npr/silverstripe-opauth', 'https://github.com/npr/Slim']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url)+len(url2)+len(url3)+len(url4)+len(url5)+len(url6)+len(url7)+len(url8)+len(url9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'body': 'django-cropduster\\n\\n\\ndjango-cropduster is a project that makes a form field available that\\nuses the Jcrop jQuery plugin. It is a drop-in\\nreplacement for django\\'s ImageField and allows users to generate multiple crops\\nfrom images, using predefined sizes and aspect ratios. django-cropduster\\nwas created by developers at The Atlantic. It\\nis compatible with python 2.7 and 3.4, and Django versions 1.4 - 1.8.\\n\\nInstallation\\nConfiguration\\nDocumentation & Examples\\nLicense\\n\\nInstallation\\nThe recommended way to install django-cropduster is from PyPI:\\n    pip install django-cropduster\\n\\nAlternatively, one can install a development copy of django-cropduster from\\nsource:\\n    pip install -e git+git://github.com/theatlantic/django-cropduster.git#egg=django-cropduster\\n\\nIf the source is already checked out, use setuptools:\\n    python setup.py develop\\n\\nConfiguration\\nTo enable django-cropduster, \"cropduster\" must be added to INSTALLED_APPS\\nin settings.py and you must include cropduster.urls in your django\\nurlpatterns.\\n# settings.py\\n\\nINSTALLED_APPS = (\\n    # ...\\n    \\'cropduster\\',\\n)\\n\\n# urls.py\\n\\nurlpatterns = patterns(\\'\\',\\n    # ...\\n    url(r\\'^cropduster/\\', include(\\'cropduster.urls\\')),\\n)\\nDocumentation & Examples\\nclass Size(name, [label=None, w=None, h=None, auto=None,\\n    min_w=None, min_h=None, max_w=None, max_h=None, required=True])\\n\\nUse Size to define your crops. The auto parameter can be set to a list of\\nother Size objects that will be automatically generated based on the\\nuser-selected crop of the parent Size.\\nCropDusterField accepts the same arguments as Django\\'s built-in ImageField\\nbut with an additional sizes keyword argument, which accepts a list of\\nSize objects.\\nAn example models.py:\\nfrom cropduster.models import CropDusterField, Size\\n\\nclass ExampleModel(models.Model):\\n    MODEL_SIZES = [\\n        # array of Size objects for initial crop\\n        Size(\"large\", w=210, auto=[\\n            # array of Size objects auto cropped based on container Size\\n            Size(\\'larger\\', w=768),\\n            Size(\\'medium\\', w=85, h=113),\\n            # more sub Size objects ...\\n        ]),\\n        # more initial crop Size objects ...\\n    ]\\n\\n    image = CropDusterField(upload_to=\"your/path/goes/here\", sizes=MODEL_SIZES)\\nTo get a dictionary containing information about an image within a template,\\nuse the get_crop templatetag:\\n{% load cropduster_tags %}\\n\\n{% get_crop obj.image \\'large\\' exact_size=1 as img %}\\n\\n{% if img %}\\n<figure>\\n    <img src=\"{{ img.url }}\" width=\"{{ img.width }}\" height=\"{{ img.height }}\"\\n         alt=\"{{ img.caption }}\" />\\n    {% if img.attribution %}\\n    <figcaption>\\n        {{ img.caption }} (credit: {{ img.attribution }})\\n    </figcaption>\\n    {% endif %}\\n</figure>\\n{% endif %}\\nLicense\\nThe django code is licensed under the\\nSimplified BSD License. View\\nthe LICENSE file under the root directory for complete license and copyright\\ninformation.\\nThe Jcrop jQuery library included is used under the\\nMIT License.\\n',\n",
       "  'top_code': '\\n\\nPython\\n50.3%\\n'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pseudo for url list\n",
    "# urls = [url1, urls2, url3, url4, etc]\n",
    "# for url in urls:\n",
    "url = 'https://github.com/theatlantic/django-cropduster'\n",
    "github = []\n",
    "response = get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "dicob = {'body':body, 'top_code':code}\n",
    "github.append(dicob)\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'body': 'django-cropduster\\n\\n\\ndjango-cropduster is a project that makes a form field available that\\nuses the Jcrop jQuery plugin. It is a drop-in\\nreplacement for django\\'s ImageField and allows users to generate multiple crops\\nfrom images, using predefined sizes and aspect ratios. django-cropduster\\nwas created by developers at The Atlantic. It\\nis compatible with python 2.7 and 3.4, and Django versions 1.4 - 1.8.\\n\\nInstallation\\nConfiguration\\nDocumentation & Examples\\nLicense\\n\\nInstallation\\nThe recommended way to install django-cropduster is from PyPI:\\n    pip install django-cropduster\\n\\nAlternatively, one can install a development copy of django-cropduster from\\nsource:\\n    pip install -e git+git://github.com/theatlantic/django-cropduster.git#egg=django-cropduster\\n\\nIf the source is already checked out, use setuptools:\\n    python setup.py develop\\n\\nConfiguration\\nTo enable django-cropduster, \"cropduster\" must be added to INSTALLED_APPS\\nin settings.py and you must include cropduster.urls in your django\\nurlpatterns.\\n# settings.py\\n\\nINSTALLED_APPS = (\\n    # ...\\n    \\'cropduster\\',\\n)\\n\\n# urls.py\\n\\nurlpatterns = patterns(\\'\\',\\n    # ...\\n    url(r\\'^cropduster/\\', include(\\'cropduster.urls\\')),\\n)\\nDocumentation & Examples\\nclass Size(name, [label=None, w=None, h=None, auto=None,\\n    min_w=None, min_h=None, max_w=None, max_h=None, required=True])\\n\\nUse Size to define your crops. The auto parameter can be set to a list of\\nother Size objects that will be automatically generated based on the\\nuser-selected crop of the parent Size.\\nCropDusterField accepts the same arguments as Django\\'s built-in ImageField\\nbut with an additional sizes keyword argument, which accepts a list of\\nSize objects.\\nAn example models.py:\\nfrom cropduster.models import CropDusterField, Size\\n\\nclass ExampleModel(models.Model):\\n    MODEL_SIZES = [\\n        # array of Size objects for initial crop\\n        Size(\"large\", w=210, auto=[\\n            # array of Size objects auto cropped based on container Size\\n            Size(\\'larger\\', w=768),\\n            Size(\\'medium\\', w=85, h=113),\\n            # more sub Size objects ...\\n        ]),\\n        # more initial crop Size objects ...\\n    ]\\n\\n    image = CropDusterField(upload_to=\"your/path/goes/here\", sizes=MODEL_SIZES)\\nTo get a dictionary containing information about an image within a template,\\nuse the get_crop templatetag:\\n{% load cropduster_tags %}\\n\\n{% get_crop obj.image \\'large\\' exact_size=1 as img %}\\n\\n{% if img %}\\n<figure>\\n    <img src=\"{{ img.url }}\" width=\"{{ img.width }}\" height=\"{{ img.height }}\"\\n         alt=\"{{ img.caption }}\" />\\n    {% if img.attribution %}\\n    <figcaption>\\n        {{ img.caption }} (credit: {{ img.attribution }})\\n    </figcaption>\\n    {% endif %}\\n</figure>\\n{% endif %}\\nLicense\\nThe django code is licensed under the\\nSimplified BSD License. View\\nthe LICENSE file under the root directory for complete license and copyright\\ninformation.\\nThe Jcrop jQuery library included is used under the\\nMIT License.\\n',\n",
       "  'top_code': '\\n\\nPython\\n50.3%\\n'},\n",
       " {'body': '\\n  data-visuals-create\\n\\n\\n\\n\\n\\n\\nA tool for generating the scaffolding needed to create a graphic or feature the Data Visuals way.\\nKey features\\n\\nüìê HTML templating with a familiar, easy Jinja2-esque format via a modified instance of a Nunjucks environment that comes with all the functionality of journalize by default.\\nüé® Supports SCSS syntax for styles compiled with the super fast reference implementation of Sass via dart-sass. All CSS is passed through autoprefixer and minified with clean-css in production.\\nüì¶ A configured instance of Webpack ready to go and optimized for a two-path modern/legacy bundle approach. Ship lean ES2015+ code to modern browsers, and a functional polyfilled/transpiled bundle to the rest!\\nüìë Full-support for ArchieML formatted Google Docs and key/value or table formatted Google Sheets. Use data you\\'ve collaborated on with reporters and editors directly in your templates.\\nüéä And so, so, so much more!\\n\\nGetting started\\nnpx @data-visuals/create feature my-great-project\\ncd feature-my-great-project-YYYY-MM # the four digit year and two digit month\\nnpm start\\n\\nWhile you can install @data-visuals/create globally and use the data-visuals-create command, we recommend using the npx method instead to ensure you are always using the latest version.\\n\\nTable of contents\\n\\nInstallation\\nUsage\\nDevelopment and testing\\nFolder structure\\n\\nconfig/\\ndata/\\nworkspace/\\nproject.config.js\\napp/\\napp/index.html, app/static.html\\napp/templates/\\napp/scripts/\\napp/styles/\\napp/assets/\\nOther directories you may see\\n\\n.tmp/\\ndist/\\n\\n\\n\\n\\nHow to work with Google Doc and Google Sheet files\\n\\nGoogle Docs\\nGoogle Sheets\\n\\n\\nSupported browsers\\nHow do JavaScript packs work?\\n\\nCreating a new entrypoint\\nConnecting an entrypoint to an HTML file\\n\\n\\nAvailable commands\\n\\nnpm start or npm run serve\\nnpm run deploy\\nnpm run data:fetch\\nnpm run assets:push\\nnpm run assets:pull\\nnpm run workspace:push\\nnpm run workspace:pull\\n\\n\\nEnvironment variables and authentication\\n\\nAWS\\nGoogle\\n\\nCLIENT_SECRETS_FILE\\nGOOGLE_TOKEN_FILE\\n\\n\\n\\n\\nLicense\\n\\nInstallation\\nWhile we recommend using the npx method, you can also install the tool globally. If you do, replace all instances of npx @data-visuals/create you see with data-visuals-create.\\nnpm install -g @data-visuals/create\\nUsage\\nnpx @data-visuals/create <project-type> <slug>\\nCurrently there are two project types available ‚Äî graphic and feature.\\nnpx @data-visuals/create graphic school-funding\\nThis will create a directory for you, copy in the files, install the dependencies, and do your first git commit.\\nThe directory name will be formatted like this:\\n<project-type>-<slug>-<year>-<month>\\n\\nUsing the example command above, it would be the following:\\ngraphic-school-funding-2018-01\\n\\nThis is to ensure consistent naming of our directories!\\nDevelopment and testing\\nIf you make changes locally to @data-visuals/create and want to test them, you can run data-visuals-create/bin/data-visuals-create <project-type> <slug> to generate a graphic or feature and see if your changes were included. Run the command one level above this repo, or you\\'ll create a graphic or feature within data-visuals-create.\\nFolder structure\\nAfter creation, your project directory should look something like this:\\nyour-project/\\n  README.md\\n  node_modules/\\n  config/\\n  data/\\n  workspace/\\n  package.json\\n  project.config.js\\n  app/\\n    index.html\\n    templates/\\n    styles/\\n    scripts/\\n    assets/\\n\\nHere are the highlights of what each file/directory represents:\\nconfig/\\nThis is the directory of all the configuration and tasks that power the kit. You probably do not need to ever go in here! (And eventually this will be abstracted away.)\\ndata/\\nWhere data downloaded and processed with npm run data:fetch ends up. You are also free to manually (or via your own scripts!) put data files here - they will get pulled in too! Be aware that the only compatible data files that belong here are ones that quaff knows how to consume, otherwise it will ignore them.\\nworkspace/\\nThe workspace directory is for storing all of your analysis, production and raw data files. It\\'s important to use this directory for these files (instead of app/assets/ or data/) so we can keep them out of GitHub and away from other parts of the kit. You interact with it using the npm run workspace:push and npm run workspace:pull commands.\\nproject.config.js\\nWhere all the configuration for a project belongs. This is where you can change the S3 deploy parameters, manage the Google Drive documents that sync with this project, set up a bespoke API or add custom filters to Nunjucks.\\napp/\\nWhere you\\'ll spend most of your time! Here are where all the assets that go into building your project live.\\napp/index.html, app/static.html\\nThe starter HTML pages provided by the kit. index.html is for scripted graphics that require additional JavaScript, and static.html is for graphics that do not, like Illustrator embeds. Feel free to rename them!\\nIf your project is only a single page (or graphic), you can pick one of them where you do all your HTML work. No special configuration is required to create new HTML files - just creating a new .html file in in the app directory (but not within app/scripts/ or /app/templates/ - HTML files have special meanings in those directories) is enough to tell the kit about new pages it should compile.\\nWhen embedding graphics other than index.html, remember to add the name of the template to the end of the embed link. The default link points to index.\\napp/templates/\\nWhere all the Nunjucks templates (including the base.html template that app/index.html inherits from), includes and macros live.\\napp/scripts/\\nWhere all of our JavaScript files live. Within this folder there are a number of helpful utilities and scripts we\\'ve created across tons of projects. JavaScript imports work as you\\'d expect, but the app/scripts/packs/ directory is special - learn more about it in the How do JavaScript packs work? section.\\napp/styles/\\nAll the SCSS files that are used to compile the CSS files live here. This includes all of our house styles and variables (app/styles/_variables.scss). app/styles/main.scss is the primary entrypoint - any changes you make will either need to be in this file or be imported into it.\\napp/assets/\\nWhere all other assets should live. This includes images, font files, any JSON or CSV files you want to directly interact with in your JavaScript - these files are post-processed and deployed along with the other production files. Be aware, anything in this directory will technically be public on deploy. Use workspace/ or data/ instead for things that shouldn\\'t be public.\\nOther directories you may see\\n.tmp/\\nThis is a temporary folder where files compiled during development will be placed. You can safely ignore it.\\ndist/\\nThis is the compiled project and the result of running npm run build.\\nHow to work with Google Doc and Google Sheet files\\n@data-visuals/create projects support downloading ArchieML-formatted Google Docs and correctly-formatted Google Sheets directly from Google Drive for use within your templates. All files you want to use in your projects should be listed in project.config.js under the files key. You are not limited to one of each, either! (Our current record is seven Google Docs and two Google Sheets in a single project.)\\n{ // ...\\n  /**\\n    * Any Google Doc and Google Sheet files to be synced with this project.\\n    */\\n  files: [\\n    {\\n      fileId: \\'<the-document-id-from-the-url>\\',\\n      type: \\'doc\\',\\n      name: \\'text\\',\\n    },\\n    {\\n      fileId: \\'<the-sheet-id-from-the-url>\\',\\n      type: \\'sheet\\',\\n      name: \\'data\\',\\n    },\\n  // ...\\n}\\nEach object representing a file needs three things:\\nfileId\\nThe fileId key represents the ID of a Google Doc or Google Sheet. This is most easily found in the URL of a document when you have it open in your browser.\\ntype\\nThe type key is used to denote whether this is a Google Doc (doc) or a Google Sheet (sheet). This controls how it gets processed.\\nname\\nThe name key controls what filename it will receive once it\\'s put in the data/ directory. So if the name is hello, it\\'ll be saved to data/hello.json.\\nGoogle Docs\\nArchieML Google Docs work as documented on the ArchieML site. This includes the automatic conversion of links to <a> tags!\\nOur kit can display variables pulled in from Google Docs in the template. This is helpful when we want to show data in our text that is in the data/ folder. Nunjucks finds the variable syntax (anything in curly braces) in our Google Doc text and displays the corresponding value.\\nBy default, Nunjucks has access to every file in our data/ folder as an object. For example, if there are two files in the data/ folder named data.json and text.json respectively, it will be structured as:\\n{\\n  \"text\": {\\n    \"title\": \"Phasellus venenatis dapibus ante, vel sodales sem blandit sed.\",\\n  },\\n  \"data\": {\\n    \"keyvalue_sheet\": {\\n      \"key1\": \"value1\",\\n    }\\n  }\\n}\\nYou can then reference values in this data object as a variable, i.e. {{ data.keyvalue_sheet.key1 }} in the Google Doc.\\nYou can also pass in your own data object for Nunjucks to reference to the prose, raw and text macros. This will override any values in the default data object.\\nGoogle Sheets\\nGoogle Sheets processed by @data-visuals/create may potentially require some additional configuration. Each sheet (or tab) in a Google Sheet is converted separately by the kit, and keyed-off in the output object by the name of the sheet.\\nBy default it treats every sheet in a Google Sheet as being formatted as a table. In other words, every row is considered an item, and the header row determines the key of each value in a column.\\nThe Google Sheets processor also supports a key-value format as popularized by copytext (and its Node.js counterpart). This treats everything in the first column as the key, and everything in the second column as the value matched to its key. Every other column is ignored.\\nTo activate the key-value format, add :kv to the end of a sheet\\'s filename. (For consistency you can also use :table to tell the processor to treat a sheet as a table, but it is not required due to it being the default.)\\nIf there are any sheets you want to exclude from being processed, you can do it via two ways: hide them using the native hide mechanism in Google Sheets, or add :skip to the end of the sheet name.\\nSupported browsers\\n@data-visuals/create projects use a two-prong JavaScript bundling method to ship a lean, modern bundle for evergreen browsers and and a polyfilled, larger bundle for legacy browsers. It uses the methods promoted in Philip Walton\\'s Deploying ES2015+ Code in Production Today blog post and determines browser support based on whether a browser understands ES Module syntax. If a browser does, it gets the modern bundle. If it doesn\\'t, it gets the legacy bundle.\\nIn practice this means you mostly do not have to worry about it - as long as you\\'re using the JavaScript packs correctly everything should just work. In terms of actual browsers, while we do still currently do a courtesy check of how things look in Internet Explorer 11, it\\'s not considered a dealbreaker if a complicated feature or graphic does not work there and would require extensive work to ensure compatibility.\\nFor CSS we currently pass the following to autoprefixer.\\n\"browserslist\": [\"> 0.5%\", \"last 2 versions\", \"Firefox ESR\", \"not dead\"]\\nHow do JavaScript packs work?\\nProjects created with @data-visuals/create borrow a Webpack approach from rails/webpacker to manage JavaScript entrypoints without configuration. To get the right scripts into the right pages, you have to do two things.\\nCreating a new entrypoint\\nBy default every project will come with an entrypoint file located at app/scripts/packs/main.js, but you\\'re not required to only use that if it makes sense to have different sets of scripts for different pages. Any JavaScript file that exists within app/scripts/packs/ is considered a Webpack entrypoint.\\ntouch app/scripts/packs/maps.js\\n# Now the build task will create a new entrypoint called `maps`! Don\\'t forget to add your code.\\nConnecting an entrypoint to an HTML file\\nBecause there\\'s a lot more going on behind the scenes than just adding a <script> tag, you have to set a special variable in a template in order to get the right entrypoint into the right HTML file.\\nSet jsPackName anywhere in the HTML file to the name of your entrypoint (without the extension) to route the right JavaScript files to it.\\n{% set jsPackName = \\'map\\' %}\\n{# This is now using the new entrypoint we created above #}\\nPack entrypoints can be used multiple times across multiple pages, so if your code allows for it feel free to add an entrypoint to multiple pages. (You can also add jsPackName to the base app/templates/base.html file and have it inserted in every page that inherits from it).\\nAvailable commands\\nAll project templates share the same build commands.\\nnpm start or npm run serve\\nThe main command for development. This will build your HTML pages, prepare your SCSS files and compile your JavaScript. A local server is set up so you can view the project in your browser.\\nnpm run deploy\\nThe main command for deployment. It will always run npm run build first to ensure the compiled version is up-to-date. Use this when you want to put your project online. This will use the bucket and folder values in the project.config.js file to determine where it should be deployed on S3. Make sure those are set the appropriate values!\\nnpm run data:fetch\\nThis command uses the array of files listed under the files key in project.config.js to download data to the project. This data will be processed and made available in the data folder in the root of the project.\\nYou can also set dataDir in project.config.js to change the location of that directory if necessary.\\nnpm run assets:push\\nThis pushes all the raw files found in the app/assets directory to S3 to a raw_assets directory. This makes it possible for collaborators on the project to sync up with your assets when they run npm run assets:pull. This prevents potentially large assets like photos and audio clips from ending up in GitHub. This also runs automatically when npm run deploy is used.\\nnpm run assets:pull\\nPulls any raw assets that have been pushed to S3 back down to the project\\'s app/assets directory. Good for ensuring you have the same files as anyone else who is working on the project.\\nnpm run workspace:push\\nThe workspace directory is for storing all of your analysis, production and raw data files. It\\'s important to use this directory for these files (instead of assets or data) so we can keep them out of GitHub. This command will push the contents of the workspace directory to S3.\\nnpm run workspace:pull\\nPulls any workspace files that have been pushed to S3 back down to the project\\'s local workspace directory. This is helpful for ensuring you\\'re in sync with another developer.\\nEnvironment variables and authentication\\nAny projects created with data-visuals-create assume you\\'re working within a Texas Tribune environment, but it is possible to point AWS (used for deploying the project and assets to S3) and Google\\'s API (used for interfacing with Google Drive) at your own credentials.\\nAWS\\nProjects created with data-visuals-create support two of the built-in ways that aws-sdk can authenticate. If you are already set up with the AWS shared credentials file (and those credentials are allowed to interact with your S3 buckets), you\\'re good to go. aws-sdk will also recognize the AWS credential environmental variables.\\nGoogle\\nThe interface with Google Drive within data-visuals-create projects currently only supports using Oauth2 credentials to speak to the Google APIs. This requires a set of OAuth2 credentials that will be used to generate and save an access token to your computer. data-visuals-create projects have hardcoded locations for the credential file and token file, but you may override those with environmental variables.\\nCLIENT_SECRETS_FILE\\ndefault: ~/.tt_kit_google_client_secrets.json\\nGOOGLE_TOKEN_FILE\\ndefault: ~/.google_drive_fetch_token\\nLicense\\nMIT\\n',\n",
       "  'top_code': '\\n\\nJavaScript\\n61.3%\\n'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://github.com/theatlantic/django-cropduster', 'https://github.com/texastribune/data-visuals-create']\n",
    "github = []\n",
    "for url in urls:\n",
    "    response = get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    body = soup.find('article', class_='markdown-body entry-content container-lg').text\n",
    "    code = soup.find('a', class_='d-inline-flex flex-items-center flex-nowrap link-gray no-underline text-small mr-3').text\n",
    "    dicob = {'body':body, 'top_code':code}\n",
    "    github.append(dicob)\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ddd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
